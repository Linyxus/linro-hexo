---
title: 零基础理解卷积神经网络[1]
date: 2017-08-02 19:49:38
tags:
- tutorial
- cnn
categories:
- Machine Learning

---

[零基础理解卷积神经网络 - 索引页](/Machine-Learning/guide-to-cnn-index/)

本文译自[A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)，已征得原作者同意。

![img](https://adeshpande3.github.io/assets/Cover.png)

## 引言

卷积神经网络，这玩意儿乍一听像是生物和数学再带点计算机技术混合起来的奇怪东西。奇怪归奇怪，不得不说，卷积神经网络是计算机视觉领域最有影响力的创造之一。

<!-- more -->

2012年是卷积神经网络崛起之年。这一年，Alex Krizhevsky带着卷积神经网络参加了ImageNet竞赛，其重要程度相当于奥运会。并一鸣惊人，将识别错误率从26%降到了15%,。从那开始，很多公司开始使用深度学习作为他们服务的核心。比如，Facebook在他们的自动标记算法中使用了它，Google在照片搜索中使用了，Amazon在商品推荐中使用，Printerst应用于为他们的家庭饲养服务提供个性化定制，而Instagram应用于他们的搜索引擎。

![](https://adeshpande3.github.io/assets/Companies.png)

然而，神经网络最开始也是最多的应用领域是图像处理。那我们就挑这块来聊聊，怎样使用卷积神经网络（下面简称CNN）来进行图像分类。

## 问题描述

图像分类是指，向机器输入一张图片，然后机器告诉我们这张图片的类别（一只猫，一条狗等等），或者如果它不确定的话，它会告诉我们属于某个类别的可能性（很可能是条狗但是我不太确定）。对我们人类来说，这件事情简单的不能再简单了，从出生起，我们就可以很快地识别周围的物体是什么。当我们看到一个场景，我们总能快速地识别出所有物体，甚至是下意识的，没有经过有意的思考。但这种能力，机器并不具有。所以我们更加要好好珍惜自己的大脑呀！\_(:зゝ∠)\_

![img](https://adeshpande3.github.io/assets/Corgi3.png)

## 输入与输出

电脑和人看到的图片并不相同。当我们输入一张图片时，电脑得到的只是一个数组，记录着像素的信息。数组的大小由图像的清晰度和大小决定。假设我们有一张jpg格式的480\*480大小的图片，那么表示它的数组便是480\*480\*3大小的。数组中所有数字都描述了在那个位置处的像素信息，大小在[0,255]之间。

这些数字对我们来说毫无意义，但这是电脑们可以得到的唯一的信息（也足够了）。抽象而简单的说，我们需要一个接受数组为输入，输出一个数组表示属于各个类别概率的模型。

## 我们想让电脑干啥？

既然问题我们已经搞明白了，现在我们得想想办法解决它。我们想让电脑做的事情是找出不同图片之间的差别，并可以识别狗狗（举个例子）的特征。

我们人类可以通过一些与众不同的特征来识别图片，比如狗狗的爪子和狗有四条腿。同样地，电脑也可以通过识别更低层次的特征（曲线，直线）来进行图像识别。电脑用卷积层识别这些特征，并通过更多层卷积层结合在一起，就可以像人类一样识别出爪子和腿之类的高层次特征，从而完成任务。这正是CNN所做的事情的大概脉络。下面，我们进行更具体的讨论。

## 与生物学的关联

在正式开始之前，让我们先来聊聊CNN的背景故事。当你第一次听说卷积神经网络的时候，你可能就会联想到一些与神经学或者生物学有关的东西，不得不说，卷积神经网络还真的与他们有某种关系。

CNN的灵感的确来自大脑中的视觉皮层。视觉皮层某些区域中的神经元只对特定视野区域敏感。1962年，在一个Hubel与Wiesel进行的试验（[视频](https://www.youtube.com/watch?v=Cw5PKV9Rj3o)）中，这一想法被证实并且拓展了。他们发现，一些独立的神经元只有在特定方向的边界在视野中出现时才会兴奋。比如，一些神经元在水平边出现时兴奋，而另一些只有垂直边出现时才会。他们发现，所有这种类型的神经元都在一个柱状组织中，并且可以产生视觉。

在一个系统中，一些特定的组件发挥特定的作用（视觉皮层中的神经元寻找各自特定的特征）。这一想法应用于很多机器中，并且也是CNN背后的基本原理。*（译者注：作者没有说清楚。类比到CNN中，应是不同的卷积核寻找图像中不同的特征）*

## 神经网络结构

回到主题。

更详细的说，CNN的工作流程是这样的：你把一张图片传递给模型，经过一些卷积层，非线性化（激活函数），池化，以及全连层，最后得到结果。就像我们之前所说的那样，输出可以是单独的一个类型，也可以是一组属于不同类型的概率。现在，最不容易的部分来了：理解各个层的作用。

## 第一层（卷积层） - 数学描述

首先，你要搞清楚的是，什么样的数据输入了卷积层。就像我们之前提到的那样，输入是一个32 × 32 × 3（打个比方）的记录像素值的数组。现在，让我来解释卷积层是什么。解释卷积层最好的方法，是想象一个手电筒照在图片的左上角。让我们假设手电筒的光可以招到一个5 × 5的区域。现在，让我们想象这个手电筒照过了图片的所有区域。在机器学习术语中，这样一个手电筒被称为卷积核（或者说过滤器，神经元）*(kernel, filter, neuron)*。而它照到的区域被称为感知域*(receptive field)*。卷积核同样也是一个数组（其中的数被称为权重或者参数）。很重要的一点就是卷积核的深度和输入图像的深度是一样的（这保证可它能正常工作），所以这里卷积层的大小是5 × 5 × 3。

现在，让我们拿卷积核的初始位置作为例子，它应该在图像的左上角。当卷积核扫描它的感知域（也就是这张图左上角5 × 5 × 3的区域）的时候，它会将自己保存的权重与图像中的像素值相乘（或者说，矩阵元素各自相乘，注意与矩阵乘法区分），所得的积会相加在一起（在这个位置，卷积核会得到5 × 5 × 3 = 75个积）。现在你得到了一个数字。然而，这个数字只表示了卷积核在图像左上角的情况。现在，我们重复这一过程，让卷积核扫描完整张图片，（下一步应该往右移动一格，再下一步就再往右一格，以此类推），每一个不同的位置都产生了一个数字。当扫描完整张图片以后，你会得到一组新的28 × 28 × 1的数。*（译者注：(32 - 5 + 1) × (32 - 5 + 1) × 1）*。这组数，我们称为激活图或者特征图*(activation map or feature map)*。

![img](https://adeshpande3.github.io/assets/ActivationMap.png)

如果增加卷积核的数目，比如，我们现在有两个卷积核，那么我们就会得到一个28 × 28 × 2的数组。通过使用更多的卷积核，我们可以更好的保留数据的空间尺寸。

在数学层面上说，这就是卷积层所做的事情。

## 第一层（卷积层） - 更高角度

让我们来谈谈，从更高角度来说，卷积在做什么。每一个卷积核都可以被看做特征识别器。我所说的特征，是指直线、简单的颜色、曲线之类的东西。这些都是所有图片共有的特点。拿一个7 × 7 × 3的卷积核作为例子，它的作用是识别一种曲线。（在这一章节，简单起见，我们忽略卷积核的深度，只考虑第一层的情况）。作为一个曲线识别器，这个卷积核的结构中，曲线区域内的数字更大。（记住，卷积核是一个数组）

![img](https://adeshpande3.github.io/assets/Filter.png)

现在我们来直观的看看这个。举个例子，假设我们要把这张图片分类。让我们把我们手头的这个卷积核放在图片的左上角。

![img](https://adeshpande3.github.io/assets/OriginalAndFilter.png)

记住，我们要做的事情是把卷积核中的权重和输入图片中的像素值相乘。

![img](https://adeshpande3.github.io/assets/FirstPixelMulitiplication.png)

*(译者注：图中最下方应是由于很多都是0所以把0略过不写了。)*

基本上，如果输入图像中有与卷积核代表的形状很相似的图形，那么所有乘积的和会很大。现在我们来看看，如果我们移动了卷积核呢？

![img](https://adeshpande3.github.io/assets/SecondMultiplication.png)

可以看到，得到的值小多了！这是因为感知域中没有与卷积核表示的相一致的形状。还记得吗，卷积层的输出是一张激活图。所以，在单卷积核卷积的简单情况下，假设卷积核是一个曲线识别器，那么所得的激活图会显示出哪些地方最有可能有曲线。在这个例子中，我们所得激活图的左上角的值为6600。这样大的数字表明很有可能这片区域中有一些曲线，从而导致了卷积核的激活*（译者注：也就是产生了很大的数值。）*而激活图中右上角的数值是0，因为那里没有曲线来让卷积核激活（简单来说就是输入图像的那片区域没有曲线）。

但请记住，这只是一个卷积核的情况，只有一个找出向右弯曲的曲线的卷积核。我们可以添加其他卷积核，比如识别向左弯曲的曲线的。卷积核越多，激活图的深度就越深，我们得到的关于输入图像的信息就越多。

> 在文中提到的卷积核的主要目的是说明，是经过简化的。在下图中你会看到真正的经过训练后的神经网络中第一层卷积层中卷积核可视化后的样子。不管怎样，道理还是一样的。第一层的卷积核扫描整张网络，并在识别到相应特征时激活。
>
> ![img](https://adeshpande3.github.io/assets/FirstLayers.png)

## 走向网络的深处

在传统的CNN结构中，还会有其他层穿插在卷积层之间。我强烈建议有兴趣的人去阅览并理解他们。但总的来说，他们提供了非线性化，保留了数据的维度，有助于提升网络的稳定度并且抑制过拟合。一个经典的CNN结构是这样的：

![img](https://adeshpande3.github.io/assets/Table.png)

网络的最后一层很重要，我们稍后会讲到它。

现在，然我们回头看看我们已经学到了什么。

我们讲到了第一层卷积层的卷积核的目的是识别特征，他们识别像曲线和边这样的低层次特征。但可以想象，如果想预测一个图片的类别，必须让网络有能力识别高层次的特征，例如手、爪子或者耳朵。让我们想想网络第一层的输出是什么。假设我们有5个5 × 5 × 3的卷积核，输入图像是32 × 32 × 3的，那么我们会得到一个28 × 28 × 5的数组。来到第二层卷积层，第一层的输出便成了第二层的输入。这有些难以可视化。第一层的输入是原始图片，可第二层的输入只是第一层产生的激活图，激活图的每一层都表示了低层次特征的出现位置。如果用一些卷积核处理它，得到的会是表示高层次特征出现的激活图。这些特征的类型可能是半圆（曲线和边的组合）或者矩形（四条边的组合）。随着卷积层的增多，到最后，你可能会得到可以识别手写字迹、粉色物体等等的卷积核。

如果，你想知道更多关于可视化卷积核*（译者注：所识别的内容）*的信息，可以看这篇[研究报告](http://www.matthewzeiler.com/pubs/arxive2013/arxive2013.pdf)，以及这个[视频](https://www.youtube.com/watch?v=AgkfIQ4IGaM)。

还有一件事情很有趣，当网络越来越深，卷积核会有越来越大的相对于输入图像的感知域。这意味着他们有能力考虑来自输入图像的更大范围的信息（或者说，他们对一片更大的像素区域负责）。

***未完待续***