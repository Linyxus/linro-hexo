---
title: 零基础理解卷积神经网络[1]
date: 2017-08-02 19:49:38
tags:
- tutorial
- cnn
categories:
- Machine Learning

---

[零基础理解卷积神经网络 - 索引页](/Machine-Learning/guide-to-cnn-index/)

本文译自[A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)，已征得原作者同意。

![img](https://adeshpande3.github.io/assets/Cover.png)

## 引言

卷积神经网络，这玩意儿乍一听像是生物和数学再带点计算机技术混合起来的奇怪东西。奇怪归奇怪，不得不说，卷积神经网络是计算机视觉领域最有影响力的创造之一。

<!-- more -->

2012年是卷积神经网络崛起之年。这一年，Alex Krizhevsky带着卷积神经网络参加了ImageNet竞赛（其重要程度相当于奥运会）并一鸣惊人，将识别错误率从26%降到了15%,。从那开始，很多公司开始使用深度学习作为他们服务的核心。比如，Facebook在他们的自动标记算法中使用了它，Google在照片搜索中使用了，Amazon在商品推荐中使用，Printerst应用于为他们的家庭饲养服务提供个性化定制，而Instagram应用于他们的搜索引擎。

![](https://adeshpande3.github.io/assets/Companies.png)

然而，神经网络最开始也是最多的应用领域是图像处理。那我们就挑这块来聊聊，怎样使用卷积神经网络（下面简称CNN）来进行图像分类。

## 问题描述

图像分类是指，向机器输入一张图片，然后机器告诉我们这张图片的类别（一只猫，一条狗等等），或者如果它不确定的话，它会告诉我们属于某个类别的可能性（很可能是条狗但是我不太确定）。对我们人类来说，这件事情简单的不能再简单了，从出生起，我们就可以很快地识别周围的物体是什么。当我们看到一个场景，我们总能快速地识别出所有物体，甚至是下意识的，没有经过有意的思考。但这种能力，机器并不具有。所以我们更加要好好珍惜自己的大脑呀！\_(:зゝ∠)\_

![img](https://adeshpande3.github.io/assets/Corgi3.png)

## 输入与输出

电脑和人看到的图片并不相同。当我们输入一张图片时，电脑得到的只是一个数组，记录着像素的信息。数组的大小由图像的清晰度和大小决定。假设我们有一张jpg格式的480\*480大小的图片，那么表示它的数组便是480\*480\*3大小的。数组中所有数字都描述了在那个位置处的像素信息，大小在[0,255]之间。

这些数字对我们来说毫无意义，但这是电脑们可以得到的唯一的信息（也足够了）。抽象而简单的说，我们需要一个接受数组为输入，输出一个数组表示属于各个类别概率的模型。

## 我们想让电脑干啥？

既然问题我们已经搞明白了，现在我们得想想办法解决它。我们想让电脑做的事情是找出不同图片之间的差别，并可以识别狗狗（举个例子）的特征。

我们人类可以通过一些与众不同的特征来识别图片，比如狗狗的爪子和狗有四条腿。同样地，电脑也可以通过识别更低层次的特征（曲线，直线）来进行图像识别。电脑用卷积层识别这些特征，并通过更多层卷积层结合在一起，就可以像人类一样识别出爪子和腿之类的高层次特征，从而完成任务。这正是CNN所做的事情的大概脉络。下面，我们进行更具体的讨论。

## 与生物学的关联

在正式开始之前，我们先来聊聊CNN的背景故事。当你第一次听说卷积神经网络的时候，你可能就会联想到一些与神经学或者生物学有关的东西，不得不说，卷积神经网络还真的与他们有某种关系。

CNN的灵感的确来自大脑中的视觉皮层。视觉皮层某些区域中的神经元只对特定视野区域敏感。1962年，在一个Hubel与Wiesel进行的试验（[视频](https://www.youtube.com/watch?v=Cw5PKV9Rj3o)）中，这一想法被证实并且拓展了。他们发现，一些独立的神经元只有在特定方向的边界在视野中出现时才会兴奋。比如，一些神经元在水平边出现时兴奋，而另一些只有垂直边出现时才会。并且所有这种类型的神经元都在一个柱状组织中，并且被认为有能力产生视觉。

在一个系统中，一些特定的组件发挥特定的作用（视觉皮层中的神经元寻找各自特定的特征）。这一想法应用于很多机器中，并且也是CNN背后的基本原理。*（译者注：作者没有说清楚。类比到CNN中，应是不同的卷积核寻找图像中不同的特征）*

## 神经网络结构

回到主题。

更详细的说，CNN的工作流程是这样的：你把一张图片传递给模型，经过一些卷积层，非线性化（激活函数），池化，以及全连层，最后得到结果。就像我们之前所说的那样，输出可以是单独的一个类型，也可以是一组属于不同类型的概率。现在，最不容易的部分来了：理解各个层的作用。

## 第一层（卷积层） - 数学描述

首先，你要搞清楚的是，什么样的数据输入了卷积层。就像我们之前提到的那样，输入是一个32 × 32 × 3（打个比方）的记录像素值的数组。现在，让我来解释卷积层是什么。解释卷积层最好的方法，是想象一个手电筒照在图片的左上角。让我们假设手电筒的光可以招到一个5 × 5的区域。现在，让我们想象这个手电筒照过了图片的所有区域。在机器学习术语中，这样一个手电筒被称为卷积核（或者说过滤器，神经元）*(kernel, filter, neuron)*。而它照到的区域被称为感知域*(receptive field)*。卷积核同样也是一个数组（其中的数被称为权重或者参数）。很重要的一点就是卷积核的深度和输入图像的深度是一样的（这保证可它能正常工作），所以这里卷积核的大小是5 × 5 × 3。

现在，让我们拿卷积核的初始位置作为例子，它应该在图像的左上角。当卷积核扫描它的感知域（也就是这张图左上角5 × 5 × 3的区域）的时候，它会将自己保存的权重与图像中的像素值相乘（或者说，矩阵元素各自相乘，注意与矩阵乘法区分），所得的积会相加在一起（在这个位置，卷积核会得到5 × 5 × 3 = 75个积）。现在你得到了一个数字。然而，这个数字只表示了卷积核在图像左上角的情况。现在，我们重复这一过程，让卷积核扫描完整张图片，（下一步应该往右移动一格，再下一步就再往右一格，以此类推），每一个不同的位置都产生了一个数字。当扫描完整张图片以后，你会得到一组新的28 × 28 × 1的数。*（译者注：(32 - 5 + 1) × (32 - 5 + 1) × 1）*。这组数，我们称为激活图或者特征图*(activation map or feature map)*。

![img](https://adeshpande3.github.io/assets/ActivationMap.png)

如果增加卷积核的数目，比如，我们现在有两个卷积核，那么我们就会得到一个28 × 28 × 2的数组。通过使用更多的卷积核，我们可以更好的保留数据的空间尺寸。

在数学层面上说，这就是卷积层所做的事情。

## 第一层（卷积层） - 更高角度

让我们来谈谈，从更高角度来说，卷积在做什么。每一个卷积核都可以被看做特征识别器。我所说的特征，是指直线、简单的颜色、曲线之类的东西。这些都是所有图片共有的特点。拿一个7 × 7 × 3的卷积核作为例子，它的作用是识别一种曲线。（在这一章节，简单起见，我们忽略卷积核的深度，只考虑第一层的情况）。作为一个曲线识别器，这个卷积核的结构中，曲线区域内的数字更大。（记住，卷积核是一个数组）

![img](https://adeshpande3.github.io/assets/Filter.png)

现在我们来直观的看看这个。举个例子，假设我们要把这张图片分类。让我们把我们手头的这个卷积核放在图片的左上角。

![img](https://adeshpande3.github.io/assets/OriginalAndFilter.png)

记住，我们要做的事情是把卷积核中的权重和输入图片中的像素值相乘。

![img](https://adeshpande3.github.io/assets/FirstPixelMulitiplication.png)

*(译者注：图中最下方应是由于很多都是0所以把0略过不写了。)*

基本上，如果输入图像中有与卷积核代表的形状很相似的图形，那么所有乘积的和会很大。现在我们来看看，如果我们移动了卷积核呢？

![img](https://adeshpande3.github.io/assets/SecondMultiplication.png)

可以看到，得到的值小多了！这是因为感知域中没有与卷积核表示的相一致的形状。还记得吗，卷积层的输出是一张激活图。所以，在单卷积核卷积的简单情况下，假设卷积核是一个曲线识别器，那么所得的激活图会显示出哪些地方最有可能有曲线。在这个例子中，我们所得激活图的左上角的值为6600。这样大的数字表明很有可能这片区域中有一些曲线，从而导致了卷积核的激活*（译者注：也就是产生了很大的数值。）*而激活图中右上角的数值是0，因为那里没有曲线来让卷积核激活（简单来说就是输入图像的那片区域没有曲线）。

但请记住，这只是一个卷积核的情况，只有一个找出向右弯曲的曲线的卷积核。我们可以添加其他卷积核，比如识别向左弯曲的曲线的。卷积核越多，激活图的深度就越深，我们得到的关于输入图像的信息就越多。

> 在文中提到的卷积核的主要目的是说明，是经过简化的。在下图中你会看到真正的经过训练后的神经网络中第一层卷积层中卷积核可视化后的样子。不管怎样，道理还是一样的。第一层的卷积核扫描整张网络，并在识别到相应特征时激活。
>
> ![img](https://adeshpande3.github.io/assets/FirstLayers.png)

## 走向网络的深处

在传统的CNN结构中，还会有其他层穿插在卷积层之间。我强烈建议有兴趣的人去阅览并理解他们。但总的来说，他们提供了非线性化，保留了数据的维度，有助于提升网络的稳定度并且抑制过拟合。一个经典的CNN结构是这样的：

![img](https://adeshpande3.github.io/assets/Table.png)

网络的最后一层很重要，我们稍后会讲到它。

现在，然我们回头看看我们已经学到了什么。

我们讲到了第一层卷积层的卷积核的目的是识别特征，他们识别像曲线和边这样的低层次特征。但可以想象，如果想预测一个图片的类别，必须让网络有能力识别高层次的特征，例如手、爪子或者耳朵。让我们想想网络第一层的输出是什么。假设我们有5个5 × 5 × 3的卷积核，输入图像是32 × 32 × 3的，那么我们会得到一个28 × 28 × 5的数组。来到第二层卷积层，第一层的输出便成了第二层的输入。这有些难以可视化。第一层的输入是原始图片，可第二层的输入只是第一层产生的激活图，激活图的每一层都表示了低层次特征的出现位置。如果用一些卷积核处理它，得到的会是表示高层次特征出现的激活图。这些特征的类型可能是半圆（曲线和边的组合）或者矩形（四条边的组合）。随着卷积层的增多，到最后，你可能会得到可以识别手写字迹、粉色物体等等的卷积核。

如果，你想知道更多关于可视化卷积核的信息，可以看这篇[研究报告](http://www.matthewzeiler.com/pubs/arxive2013/arxive2013.pdf)，以及这个[视频](https://www.youtube.com/watch?v=AgkfIQ4IGaM)。

还有一件事情很有趣，当网络越来越深，卷积核会有越来越大的相对于输入图像的感知域。这意味着他们有能力考虑来自输入图像的更大范围的信息（或者说，他们对一片更大的像素区域负责）。

## 全连层

到目前为止，我们已经识别出了那些高层次的特这个吧。网络最后的画龙点睛之笔是全连层。

简单地说，这一层接受输入（来自卷积层，池化层或者激活函数都可以），并输出一个N维向量，其中，N是所有有可能的类别的总数。例如，如果你想写一个识别数字的程序，那么N就是10，因为总共有10个数字。N维向量中的每一个数字都代表了属于某个类别的概率。打个比方，如果你得到了[0 0.1 0.1 0.75 0 0 0 0 0 0.05]，这代表着这张图片是1的概率是10%，是2的概率是10%，是3的概率是75%，是9的概率5%（小贴士：你还有其他表示输出的方法，但现在我只拿softmax*(译者注：一种常用于分类问题的激活函数)*来展示）。全连层的工作方式是根据上一层的输出（也就是之前提到的可以用来表示特征的激活图）来决定这张图片有可能属于哪个类别。例如，如果程序需要预测哪些图片是狗，那么全连层在接收到一个包含类似于一个爪子和四条腿的激活图时输出一个很大的值。同样的，如果要预测鸟，那么全连层会对含有翅膀和喙的激活图更感兴趣。

基本上，全连层寻找那些最符合特定类别的特征，并且具有相应的权重，来使你可以得到正确的概率。

![img](https://adeshpande3.github.io/assets/LeNet.png)

## 训练（也即：如何让网络工作）

现在让我们来说说我之前有意没有提到的神经网络的可能是最重要的一个方面。刚刚在你阅读的时候，可能会有一大堆问题想问。第一层卷积层的卷积核们是怎么知道自己该识别边还是曲线的？全连层怎么知道该找哪一种激活图？每一层中的参数是怎么确定的？机器确定参数（或者说权重）的方法叫做反向传播算法。

在讲反向传播之前，我们得回头看看一个神经网络需要什么才能工作。我们出生的时候并不知道一条狗或者一只鸟长什么样。同样的，在CNN开始之前，权重都是随机生成的。卷积核并不知道要找边还是曲线。更深的卷积层也不知道要找爪子还是喙。

等我们慢慢长大了，我们的老师和父母给我们看不同的图片，并且告诉我们那是什么（或者说，他们的类别）。这种输入一幅图像以及这幅图像所属的类别的想法，是CNN训练的基本思路。在细细讲反向传播之前，我们先假设我们有一个包含上千张不同种类的动物以及他们所属类别的训练集。

反向传播可以被分成四个不同的部分。前向传播、损失函数、反向传播和权重更新。

在前向传播的阶段，我们输入一张训练图片，并让它通过整个神经网络。对于第一个输入图像，由于所有权重都是随机生成的，网络的输出很有可能是类似于[.1 .1 .1 .1 .1 .1 .1 .1 .1 .1]的东西，一般来说并不对任一类别有偏好。具有当前权重的网络并没有能力找出低层次的特征并且总结出可能的类别。

下一步，是损失函数部分。注意，我们现在使用的是训练数据。这些数据又有图片又有类别。打个比方，第一张输入的图片是数字“3”。那么它的标签应该是[0 0 0 1 0 0 0 0 0 0]。一个损失函数可以有很多定义的方法，但比较常见的是MSE（均方误差）。被定义为$\frac{(实际-预测)^2}{2}$。

![img](https://adeshpande3.github.io/assets/Equation.png)

记变量L为损失函数的值。正如你想象的那样，在第一组训练图片输入的时候，损失函数的值可能非常非常高。来直观地看看这个问题。我们想到达CNN的预测与数据标签完全一样的点（这意味着我们的网络预测的很对）。为了到达那里，我们想要最小化误差。如果把这个看成一个微积分问题，那我们只要找到哪些权重与网络的误差关系最大。

![img](https://adeshpande3.github.io/assets/Loss.png)

这就相当于数学中的$\frac{\delta L}{\delta W}$*(译者注：对L关于W求导)*，其中，W是某个层的权重。现在，我们要对网络进行**反向传播**。这决定了哪些权重与误差的关系最大，并且决定了怎样调整他们来让误差减小。计算完这些导数以后，我们就来到了最后一步：**更新权重**。在这里，我们以与梯度相反的方向调整层中的权重。

![img](https://adeshpande3.github.io/assets/Weight.png)

学习率是一个有程序员决定的参数。一个很高的学习率意味着权重调整的幅度会很大，这可能会让模型更快的拥有一组优秀的权重。然而，一个太高的学习率可能会让调整的步伐过大，而不能精确地到达最佳点。

![img](https://adeshpande3.github.io/assets/HighLR.png)

前向传播、损失函数、反向传播和更新权重，这四个过程是一次迭代。程序会对每一组训练图片重复这一过程（一组图片通常称为一个batch）。当对每一张图片都训练完之后，很有可能你的网络就已经训练好了，权重已经被调整的很好。

## 测试

最后，为了验证CNN是否工作的很好，我们还有另一组特殊的数据。我们把这组数据中的图片输入到网络中，得到输出并和标签比较，这样就能看出网络的表现如何了。

## 免责声明

虽然这篇文章是学习CNN的一个不错的开始，但这并不是一个全面的描述。有关非线性化、池化层和网络的超参数（比如卷积核的大小，步长，边缘处理）并没有在这篇文章中讨论。还有网络结构、数据归一化、梯度消失、Dropout*(译者注：防止网络过拟合的一个方法，找不到合适的译名)*、初始化技巧、非凸优化、偏移、损失函数的选择、数据增强、标准化方法，以及有关运算的考虑、反向传播的优化等等我们都还没有讨论。

Dueces.

Part 2的翻译尚未完成。

*2017.8.5 翻译完毕*